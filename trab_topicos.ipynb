{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de Rede Neural com Caracteres\n",
    "\n",
    "## imports\n",
    "instale o pytorch e as bibliotecas das dependencias em requirements.txt antes de iniciar o código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch.optim as optim \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import kornia.augmentation as K\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configurações de funcionamento gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"codigo começou\")\n",
    "limpar_imagens = False\n",
    "usar_imagem_minima = True\n",
    "aumentar_dados = True\n",
    "vezes = 3\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparação dos dados de treino\n",
    "\n",
    "Os dados podem ser modificados eleatoriamente e aumentados, conforme configuração anterior.\n",
    "\n",
    "As modificaçẽos incluem:\n",
    "- 80% de chances de rotação entre -20 e 20 grauls; \n",
    "- 70% de chances de adição de ruido gaussiano com desvio padrão de 0.1 (intensidade do ruído); \n",
    "- 80% de chance de alterar o brilho e o contraste da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dados(tensor, labels, aumentar_dados, vezes):\n",
    "    if aumentar_dados:\n",
    "        tensor_aux = tensor\n",
    "        labels_aux = labels\n",
    "        for i in range(vezes):\n",
    "            augmentation_pipeline = K.AugmentationSequential(\n",
    "            K.RandomRotation(degrees=(-20, 20), p=0.8),\n",
    "            K.RandomGaussianNoise(mean=0.0, std=0.05, p=0.7),\n",
    "            K.RandomHorizontalFlip(p=0.5),\n",
    "            data_keys=['input']\n",
    "            )\n",
    "            tensor_aumentado = augmentation_pipeline(tensor)\n",
    "            tensor_aux = torch.cat((tensor_aux, tensor_aumentado), dim=0)\n",
    "            labels_aux = torch.cat((labels_aux, labels), dim=0)\n",
    "        tensor = tensor_aux\n",
    "        labels = labels_aux\n",
    "        #print(tensor.shape)\n",
    "\n",
    "\n",
    "    x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "        tensor, labels, test_size=0.3, random_state=1, stratify=labels\n",
    "    )\n",
    "\n",
    "    treino_dataset = TensorDataset(x_treino, y_treino)\n",
    "    teste_dataset = TensorDataset(x_teste, y_teste)\n",
    "\n",
    "    batch_size = 32\n",
    "    trainloader = DataLoader(dataset=treino_dataset, batch_size=batch_size,shuffle=True)\n",
    "    testloader = DataLoader(dataset=teste_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return trainloader, testloader, tensor, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funções para plotar graficos de erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salvar_graficos_erros_por_classe(erros, pasta=\"graficos_classes\"):\n",
    "    os.makedirs(pasta, exist_ok=True)\n",
    "    epocas = np.arange(erros.shape[0])\n",
    "\n",
    "    for classe in range(erros.shape[1]):\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(epocas, erros[:, classe], marker='o', label=f\"Classe {classe}\")\n",
    "        plt.xlabel(\"Época\")\n",
    "        plt.ylabel(\"Quantidade de Erros\")\n",
    "        plt.title(f\"Variação de Erros - Classe {classe}\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{pasta}/classe_{classe}_erro_por_epoca.png\")\n",
    "        plt.close()\n",
    "\n",
    "def salvar_grafico_barras_erro_total(erros, nome_arquivo=\"erro_total_por_classe.png\"):\n",
    "    erro_total_por_classe = erros.sum(axis=0)\n",
    "    classes = np.arange(len(erro_total_por_classe))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(classes, erro_total_por_classe, color='steelblue')\n",
    "    plt.xlabel(\"Classe\")\n",
    "    plt.ylabel(\"Erro Total\")\n",
    "    plt.title(\"Erro Total por Classe ao longo das Épocas\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(nome_arquivo)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def salvar_graficos_chute_por_classe(chutes, pasta=\"chutes_no_teste\"):\n",
    "    os.makedirs(pasta, exist_ok=True)\n",
    "    classes = np.arange(chutes.shape[0])\n",
    "\n",
    "    for classe in range(chutes.shape[1]):\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(classes, chutes[:, classe], marker='o', label=f\"Classe {classe}\")\n",
    "        plt.xlabel(\"Classes\")\n",
    "        plt.ylabel(\"Quantidade de chutes\")\n",
    "        plt.title(f\"Variação de chutes - Classe {classe}\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{pasta}/classe_{classe}_chutes_por_classe.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## redes neurais\n",
    "\n",
    "A rede neural usada é bem simples, mas eficiente.\n",
    "tem duas camadas convolucionais e duas camadas lineares.\n",
    "As primeiras vão extrair as caracteristicas mais importantes\n",
    "as segundas classificam com base na extração anterior.\n",
    "\n",
    "A rede foi tirada de um artigo que estudei para a iniciação cientifica.\n",
    "No trabalho ela foi usada para classificar imagens do MNIST.\n",
    "Mas eu alterei as entradas da rede, pois as dimenções das imagens neste caso eram bem diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, entrada):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(20, 50, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3250, 512)\n",
    "\n",
    "        self.fc2 = nn.Linear(512, 25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 3250)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, loss_fn, i):\n",
    "    loss = 0\n",
    "    for _, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)      \n",
    "            optimizer.zero_grad()                            \n",
    "            output = model(data)                               \n",
    "            loss = loss_fn(output, target)                   \n",
    "            loss.backward()                                 \n",
    "            optimizer.step()\n",
    "\n",
    "    print(f'Epoch {i} TRAIN: Last Loss: {loss:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, epoca):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in enumerate(test_loader):            # intera sobre cada dado e seu rotulo, _ descarta os index que não serão usados na função\n",
    "            data, target = data.to(device), target.to(device)       # transfere os dados e os rotulos para o dispositivo escolhido\n",
    "            outputs = model(data)                                   # gera as predictions\n",
    "            loss = F.nll_loss(outputs, target).item()               # calcula o erro\n",
    "            pred = outputs.argmax(1, keepdim=True)                  #\n",
    "            resposta = pred.eq(target.view_as(pred)).sum().item()\n",
    "            for i in range(len(target.cpu().detach().numpy())):\n",
    "                if(target[i] != pred[i][0]):\n",
    "                    erros[epoca][target[i]] +=1\n",
    "\n",
    "            correct += resposta   # calcula o numero predições corretas\n",
    "\n",
    "            all_predictions.extend(pred.cpu().numpy().flatten())\n",
    "            all_targets.extend(target.cpu().numpy().flatten())\n",
    "\n",
    "        total_samples = len(test_loader.dataset)\n",
    "        precision, recall, f1_score, _ = precision_recall_fscore_support(all_targets, all_predictions, average='weighted', zero_division=1)\n",
    "        accuracy = (correct / total_samples) * 100\n",
    "\n",
    "        with open(f\"Relatorio do Treinamento.txt\", 'a') as file:\n",
    "            file.write(f'Last Loss: {loss:.4f} | Accuracy: {accuracy:.2f}% | Correct: {correct}/{total_samples} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1_score:.4f}\\n')\n",
    "        print(f'Last Loss: {loss:.4f} | Accuracy: {accuracy:.2f}% | Correct: {correct}/{total_samples} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## acesso às imagens\n",
    "\n",
    "As imagens foram classificadas pelos grupos com tipos de arquivos diferentes, isso teve que ser ajustado durante o acesso.\n",
    "As dimensões das imagens foram padronizadas com 32 de largura e 64 de altura.\n",
    "\n",
    "Foi feito um processamento nas imagens. O fundo das imagens foi deixado completamente branco e eu destaquei melhor\n",
    "os digitos para a rede saber melhor onde ela deve focar e quais são os pixeis que realmente importam.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aminho_conjuntos = Path(f'conjuntos')\n",
    "caminhos_jpg = list(caminho_conjuntos.rglob('*.jpg'))\n",
    "caminhos_jpeg = list(caminho_conjuntos.rglob('*.jpeg'))\n",
    "caminhos_imagens = caminhos_jpg + caminhos_jpeg\n",
    "#print(f'encontrados {len(caminhos_imagens)}')\n",
    "\n",
    "largura = 32\n",
    "altura = 64\n",
    "tamanho_alvo = (largura, altura)\n",
    "\n",
    "lista_imagens = []\n",
    "lista_rotulos = []\n",
    "i = 0\n",
    "rotuloAnterior = -1\n",
    "for caminho_da_imagem in caminhos_imagens:\n",
    "    imagem = Image.open(caminho_da_imagem)\n",
    "    imagem = imagem.convert('L')\n",
    "    imagem_redimensionada = imagem.resize(tamanho_alvo, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    if limpar_imagens:\n",
    "        imagem_redimensionada = imagem_redimensionada.point(lambda v: 0 if v < 90 else 255)\n",
    "\n",
    "\n",
    "    array_imagem = np.array(imagem_redimensionada)\n",
    "    lista_imagens.append(array_imagem)\n",
    "\n",
    "    rotulo = caminho_da_imagem.parent.name\n",
    "    lista_rotulos.append(int(rotulo))\n",
    "    # if rotuloAnterior != rotulo and i<10:\n",
    "    #     i+=1\n",
    "    #     rotuloAnterior = rotulo\n",
    "    #     imagem_redimensionada.show()\n",
    "    #     print(rotulo)\n",
    "\n",
    "    # print(f'processado: {caminho_da_imagem}')\n",
    "    # print(f'rotulo: {caminho_da_imagem.parent.name}')\n",
    "    #print(f'array imagem tipo: {array_imagem.shape}')\n",
    "\n",
    "print()\n",
    "# preparação de dados para treino\n",
    "# transpor imagnes\n",
    "lista_de_imagens_t = []\n",
    "lista_tensores = []\n",
    "#for img in lista_imagens:\n",
    "    #lista_de_imagens_t.append(img.transpose((2,0,1)))\n",
    "    #print(f'transposta: {lista_de_imagens_t[0].shape}')  # deu certo\n",
    "    \n",
    "for img in lista_imagens:\n",
    "    lista_tensores.append(torch.from_numpy(img))\n",
    "    #print(f\"Tipo de dado do tensor após 'from_numpy': {lista_tensores[0].dtype}\")\n",
    "\n",
    "lista_tensores = [img.float()/255.0 for img in lista_tensores]\n",
    "#print(f'tensorfinal: {lista_tensores[0].shape}') # formato [3,64,32] dado: float32\n",
    "\n",
    "tensor = torch.stack(lista_tensores, dim=0) # empilha as dimensões\n",
    "#print(tensor.shape)\n",
    "\n",
    "#print(f\"Distribuição original das classes: {Counter(lista_rotulos)}\")\n",
    "numero_amostras = tensor.shape[0]\n",
    "#print(numero_amostras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## limitação de imagens\n",
    "\n",
    "Se tiver que usar imagem minima, ele busca qual é a classe que tem menos exemplos.\n",
    "então eu crio um tensor com as mesmas quantidades de exemplos de cada classe.\n",
    "Neste caso apenas a dimensão [0] do tensor original é alterado.\n",
    "Nos dados finais, a classe 8 possuia 21 imagens, então este foi o limitante inferior usado.\n",
    "Mas isso deixavou o treinamento muito mais complicado.\n",
    "\n",
    "Como foi feito o aumento de dados esta explicado na função egerar_dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if usar_imagem_minima:\n",
    "    tensor_achatado = tensor.reshape((numero_amostras, altura*largura))\n",
    "    rus = RandomUnderSampler(random_state=1)\n",
    "    tensor_balanceado, lista_rotulos = rus.fit_resample(tensor_achatado, lista_rotulos)\n",
    "    #print(f\"Distribuição após undersampling: {Counter(labels_balanceadas)}\")\n",
    "    tensor = torch.from_numpy(tensor_balanceado.reshape((-1, altura, largura)))\n",
    "    #print(f\"Formato do tensor balanceado: {tensor.shape}\")\n",
    "    #print(type(tensor))\n",
    "\n",
    "labels = torch.tensor(lista_rotulos, dtype=torch.long)\n",
    "#print(labels)\n",
    "tensor = tensor.unsqueeze(1)\n",
    "#print(f'formato tensor {tensor.shape}')\n",
    "\n",
    "\n",
    "\n",
    "# x_treino, x_teste, y_treino, y_teste = train_test_split(\n",
    "#     tensor,\n",
    "#     labels_balanceadas,\n",
    "#     test_size=0.3,\n",
    "#     random_state=1,\n",
    "#     stratify=labels_balanceadas\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Net(largura*altura).to(device=device)\n",
    "optimizer = optim.SGD(modelo.parameters(), lr=lr)\n",
    "loss = F.nll_loss\n",
    "\n",
    "trainloader, testloader, tensor, labels = gerar_dados(tensor, labels, aumentar_dados, vezes)\n",
    "\n",
    "EPOCA = 12\n",
    "chutes = np.zeros((25, 25))\n",
    "erros = np.zeros((EPOCA, 25))\n",
    "print(\"vai inicar treinamento\")\n",
    "for epoca in range(EPOCA):\n",
    "    train(modelo, device, trainloader, optimizer, loss,epoca)\n",
    "    test(modelo, device, testloader, epoca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## erros\n",
    "\n",
    "A obtenção dos erros é feita em uma matriz  [epocas,25]\n",
    "cada linha guarda os erros de uma epoca, e cada coluna guarda o erro de uma classe.\n",
    "\n",
    "dessa forma é possivel obter a variação dos erros de cada classe em cada epoca.\n",
    "no final ele percorre cada coluna para calcular os erros totais de cada classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"erros_por_classe.txt\", \"w\") as nota:\n",
    "    for i in range(EPOCA):\n",
    "        nota.write(f\"epoca {i}: {str(erros[i])}\\n\")\n",
    "    erros_classe = [int(erros[:,i].sum()) for i in range(25)]\n",
    "    nota.write(\"\\nclasses / erros\")\n",
    "    for i in range(25):\n",
    "        nota.write(f\"{i}: {erros_classe[i]}\\n\")\n",
    "\n",
    "salvar_graficos_erros_por_classe(erros)\n",
    "salvar_grafico_barras_erro_total(erros)\n",
    "salvar_graficos_chute_por_classe(chutes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
